{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import torch\n",
    "import imageio\n",
    "import torchvision\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##!pip install pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## CNNs for CIFAR10\n",
    "\n",
    "* https://rcalix1.github.io/DeepLearningAlgorithms/SecondEdition/chapter6_CNNs/index.html\n",
    "\n",
    "## Load and save torch model checkpoints\n",
    "\n",
    "* https://pytorch.org/tutorials/beginner/saving_loading_models.html\n",
    "\n",
    "## Data\n",
    "\n",
    "* Data: https://github.com/YoongiKim/CIFAR-10-images/tree/master\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## !pip install torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "torch.cuda.device_count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "torch.cuda.current_device()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA A30'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "torch.cuda.get_device_name(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Assign device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch_device = torch.device(\"cpu\")\n",
    "\n",
    "if torch.cuda.is_available(): \n",
    "    torch_device = torch.device(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "torch_device\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## CIFAR10 DATA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "raw_data_train = '/home/huizarn/Desktop/CIFAR-10-images-master/train/'\n",
    "\n",
    "raw_data_test  = '/home/huizarn/Desktop/CIFAR-10-images-master/test/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## PATH to checkpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PATH = \"/scratch/scholar/huizarn/CNN_model_CIFAR10\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Train data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_train = []\n",
    "labels_train  = []\n",
    "targets_train = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for folder in sorted(os.listdir(raw_data_train)):\n",
    "    for image in sorted(os.listdir(os.path.join(raw_data_train, folder))):\n",
    "        if folder not in labels_train:\n",
    "            labels_train.append(folder)\n",
    "        targets_train.append(labels_train.index(folder))\n",
    "        \n",
    "        img_arr = imageio.imread( os.path.join(raw_data_train, folder, image), pilmode=\"RGB\")\n",
    "        ## resize = torchvision.transforms.Resize(size)\n",
    "        ## crop_center = torchvision.transforms.CenterCrop(size)\n",
    "\n",
    "        img = torch.from_numpy(img_arr).permute(2, 0, 1).float()\n",
    "        ## img = resize(img)\n",
    "        ## img = crop_center(img)\n",
    "        img /= 255\n",
    "        dataset_train.append(img)\n",
    "        \n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(labels_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len( targets_train )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataset_train[3].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_train    = torch.stack( dataset_train )\n",
    "targets_train = torch.Tensor(  targets_train  ).type(   torch.LongTensor   )\n",
    "\n",
    "torch.save(   (data_train, targets_train, labels_train), \"InClass_CIFAR10_data\"     )\n",
    "\n",
    "## data1, targets1, labels1 = torch.load(\"InClass_CIFAR10_data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 3, 32, 32])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "targets_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_train[4].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "targets_train[24000:25000]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Print images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.8392, 0.8353, 0.7059,  ..., 0.2471, 0.2902, 0.2627],\n",
       "         [0.8196, 0.8353, 0.7765,  ..., 0.1961, 0.2510, 0.2353],\n",
       "         [0.8039, 0.7961, 0.7922,  ..., 0.1961, 0.2392, 0.2431],\n",
       "         ...,\n",
       "         [0.2078, 0.1647, 0.1255,  ..., 0.4275, 0.4196, 0.4314],\n",
       "         [0.2392, 0.2471, 0.2235,  ..., 0.4235, 0.4392, 0.4510],\n",
       "         [0.2314, 0.2510, 0.2275,  ..., 0.4078, 0.4275, 0.4588]],\n",
       "\n",
       "        [[0.7569, 0.7490, 0.6196,  ..., 0.2588, 0.2980, 0.2667],\n",
       "         [0.7333, 0.7490, 0.6824,  ..., 0.2078, 0.2588, 0.2471],\n",
       "         [0.7098, 0.7020, 0.6863,  ..., 0.2157, 0.2667, 0.2706],\n",
       "         ...,\n",
       "         [0.2118, 0.1647, 0.1255,  ..., 0.4000, 0.4039, 0.4196],\n",
       "         [0.2353, 0.2431, 0.2157,  ..., 0.3961, 0.4157, 0.4392],\n",
       "         [0.2235, 0.2392, 0.2157,  ..., 0.3725, 0.4039, 0.4353]],\n",
       "\n",
       "        [[0.5490, 0.5529, 0.4353,  ..., 0.1922, 0.2549, 0.2353],\n",
       "         [0.5373, 0.5569, 0.5020,  ..., 0.1412, 0.2078, 0.2039],\n",
       "         [0.5216, 0.5216, 0.5176,  ..., 0.1373, 0.1961, 0.2078],\n",
       "         ...,\n",
       "         [0.1490, 0.1176, 0.0941,  ..., 0.3608, 0.3569, 0.3608],\n",
       "         [0.1569, 0.1725, 0.1647,  ..., 0.3569, 0.3686, 0.3804],\n",
       "         [0.1333, 0.1647, 0.1569,  ..., 0.3373, 0.3569, 0.3804]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "img_tr = data_train[46000]\n",
    "img_tr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transform = T.ToPILImage()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img = transform(  img_tr  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32 at 0x2B849AF246D0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Class balance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_train_np = targets_train.numpy() \n",
    "y_train_np.shape\n",
    "\n",
    "the_set = np.unique(  y_train_np  )\n",
    "the_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "_ = plt.hist( targets_train.numpy() , bins=\"auto\" )\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Test Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_test = []\n",
    "labels_test = []\n",
    "targets_test = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for folder in sorted(os.listdir(raw_data_test)):\n",
    "    for image in sorted(os.listdir(os.path.join(raw_data_test, folder))):\n",
    "        if folder not in labels_test:\n",
    "            labels_test.append(folder)\n",
    "        targets_test.append(labels_test.index(folder))\n",
    "        \n",
    "        # Read the image in RGB mode\n",
    "        img_arr = imageio.imread(os.path.join(raw_data_test, folder, image), pilmode=\"RGB\")\n",
    "        \n",
    "        img = torch.from_numpy( img_arr ).permute( 2, 0, 1 ).float()\n",
    "        \n",
    "        img /= 255\n",
    "        dataset_test.append(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_test   = torch.stack( dataset_test )\n",
    "targets_test = torch.Tensor(  targets_test  ).type(   torch.LongTensor   )\n",
    "\n",
    "torch.save(   (data_test, targets_test, labels_test), \"InClass_CIFAR10_data_test\"     )\n",
    "\n",
    "## data1, targets1, labels1 = torch.load(\"InClass_CIFAR10_data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 3, 32, 32])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "targets_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "_ = plt.hist( targets_test.numpy() , bins=\"auto\" )\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = data_train  \n",
    "y_train = targets_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_test = data_test  \n",
    "y_test = targets_test \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Change to float 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = X_train.numpy()\n",
    "X_test  = X_test.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = X_train.astype(  np.float32  )\n",
    "X_test  = X_test.astype(   np.float32  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = torch.from_numpy(X_train )\n",
    "X_test = torch.from_numpy( X_test  )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Print shapes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_train.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_train[30000].item()\n",
    "type(y_train[30000].item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_train[30000].item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4706, 0.4784, 0.4824,  ..., 0.4863, 0.4863, 0.4863],\n",
       "         [0.4941, 0.4941, 0.4980,  ..., 0.4784, 0.4784, 0.4784],\n",
       "         [0.5255, 0.5255, 0.5255,  ..., 0.4824, 0.4824, 0.4824],\n",
       "         ...,\n",
       "         [0.8078, 0.8078, 0.8000,  ..., 0.5216, 0.4431, 0.3686],\n",
       "         [0.6941, 0.6627, 0.6431,  ..., 0.5843, 0.5176, 0.3804],\n",
       "         [0.5765, 0.5451, 0.5529,  ..., 0.4196, 0.4314, 0.4824]],\n",
       "\n",
       "        [[0.8196, 0.8157, 0.8157,  ..., 0.7961, 0.7961, 0.7961],\n",
       "         [0.8275, 0.8275, 0.8235,  ..., 0.7882, 0.7882, 0.7882],\n",
       "         [0.8471, 0.8471, 0.8392,  ..., 0.7922, 0.7922, 0.7922],\n",
       "         ...,\n",
       "         [0.8392, 0.8471, 0.8471,  ..., 0.6118, 0.5333, 0.4588],\n",
       "         [0.7451, 0.7137, 0.7020,  ..., 0.6392, 0.5725, 0.4353],\n",
       "         [0.6431, 0.6118, 0.6196,  ..., 0.4392, 0.4510, 0.5020]],\n",
       "\n",
       "        [[0.9451, 0.9451, 0.9373,  ..., 0.9176, 0.9176, 0.9176],\n",
       "         [0.9412, 0.9412, 0.9412,  ..., 0.9098, 0.9098, 0.9098],\n",
       "         [0.9412, 0.9412, 0.9373,  ..., 0.9137, 0.9137, 0.9137],\n",
       "         ...,\n",
       "         [0.7490, 0.7529, 0.7608,  ..., 0.5020, 0.4196, 0.3451],\n",
       "         [0.6745, 0.6431, 0.6275,  ..., 0.5725, 0.5059, 0.3686],\n",
       "         [0.5804, 0.5490, 0.5569,  ..., 0.4235, 0.4353, 0.4784]]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    " X_train[78]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " CIFAR_train_list = [  ( X_train[i],  y_train[i].item() )  for i in range( X_train.shape[0]   )  ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " CIFAR_test_list = [  ( X_test[i],  y_test[i].item() )  for i in range( X_test.shape[0]   )  ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 256\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dl = torch.utils.data.DataLoader( CIFAR_train_list, batch_size=batch_size, shuffle=True  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_dl = torch.utils.data.DataLoader( CIFAR_test_list, batch_size=10000, shuffle=True  )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Architectures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3072"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "32*32*3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DL_3h_net(nn.Module):\n",
    "    ## init the class\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.linear1 = nn.Linear( 32*32*3 , 200)\n",
    "        self.act1    = nn.ReLU()\n",
    "        \n",
    "        self.linear2 = nn.Linear(200 , 100)\n",
    "        self.act2   = nn.ReLU()\n",
    "        \n",
    "        self.linear3 = nn.Linear( 100 ,50)\n",
    "        self.act3    = nn.ReLU()\n",
    "        \n",
    "        self.linear4 = nn.Linear(50 , 10)\n",
    "        self.act4    = nn.Softmax(dim=1)\n",
    "        \n",
    "        ## self.norm    = nn.LayerNorm()\n",
    "        \n",
    "    ## perform inference\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x            = self.linear1(x)\n",
    "        x            = self.act1(x)\n",
    "        x            = self.linear2(x)\n",
    "        x            = self.act2(x)\n",
    "        x            = self.linear3(x)\n",
    "        x            = self.act3(x)\n",
    "      \n",
    "        x            = self.linear4(x)\n",
    "        y_pred       = self.act4(x)\n",
    "        \n",
    "        return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CNN_net(nn.Module):\n",
    "    ## init the class\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            \n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(2, 2), # output: 64 x 16 x 16\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            \n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(2, 2), # output: 128 x 8 x 8\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(2, 2), # output: 128 x 8 x 8\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ELU(),\n",
    "            nn.BatchNorm2d(256),\n",
    "            \n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.GELU(),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.MaxPool2d(2, 2), # output: 256 x 4 x 4\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.MaxPool2d(2, 2), # output: 256 x 4 x 4\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.Flatten(), \n",
    "            nn.Linear(256, 256),\n",
    "            nn.PReLU(),\n",
    "            nn.Linear(256, 12),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(12, 10),\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "        \n",
    "    ## perform inference\n",
    "    def forward(self, x):\n",
    "        \n",
    "        y_pred       = self.model( x )\n",
    "        \n",
    "        return y_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class CNNN_net(nn.Module):\n",
    "    ## init the class\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.conv4 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(128)\n",
    "        self.conv5 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(128)\n",
    "        self.conv6 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn6 = nn.BatchNorm2d(128)\n",
    "        self.conv7 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn7 = nn.BatchNorm2d(128)\n",
    "        self.conv8 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn8 = nn.BatchNorm2d(256)\n",
    "        self.conv9 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn9 = nn.BatchNorm2d(256)\n",
    "        self.conv10 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn10 = nn.BatchNorm2d(256)\n",
    "\n",
    "        self.fc1 = nn.Linear(256, 256)\n",
    "        self.fc2 = nn.Linear(256, 20)\n",
    "        self.fc3 = nn.Linear(20, 10)\n",
    "\n",
    "    ## perform inference\n",
    "    def forward(self, x):\n",
    "        out = F.leaky_relu(self.bn1(self.conv1(x)))\n",
    "        out = F.leaky_relu(self.bn2(self.conv2(out)))\n",
    "        out = F.max_pool2d(out, 2, 2) # output: 32 x 16 x 16\n",
    "        out = F.dropout(out, 0.35)\n",
    "\n",
    "        out = F.leaky_relu(self.bn3(self.conv3(out)))\n",
    "        out = F.leaky_relu(self.bn4(self.conv4(out)))\n",
    "        out = F.max_pool2d(out, 2, 2) # output: 64 x 8 x 8\n",
    "        out = F.dropout(out, 0.35)\n",
    "\n",
    "        out = F.leaky_relu(self.bn5(self.conv5(out)))\n",
    "        out = F.elu(self.bn6(self.conv6(out)))\n",
    "        out = F.max_pool2d(out, 2, 2) # output: 128 x 4 x 4\n",
    "        out = F.dropout(out, 0.35)\n",
    "\n",
    "        out = F.leaky_relu(self.bn7(self.conv7(out)))\n",
    "        out = F.leaky_relu(self.bn8(self.conv8(out)))\n",
    "        out = F.max_pool2d(out, 2, 2) # output: 256 x 2 x 2\n",
    "        out = F.dropout(out, 0.35)\n",
    "\n",
    "        out = F.elu(self.bn9(self.conv9(out)))\n",
    "        out = F.leaky_relu(self.bn10(self.conv10(out)))\n",
    "        out = F.max_pool2d(out, 2, 2) # output: 256 x 1 x 1\n",
    "        out = F.dropout(out, 0.35)\n",
    "\n",
    "        out = out.view(out.size(0), -1) # flatten\n",
    "        out = F.elu(self.fc1(out))\n",
    "        out = F.leaky_relu(self.fc2(out))\n",
    "        out = F.log_softmax(self.fc3(out), dim=1)\n",
    "        y_pred = out\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MLP_net(nn.Module):\n",
    "    ## init the class\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.linear1 = nn.Linear( 32*32*3 ,20)\n",
    "        self.act1    = nn.LeakyReLU()\n",
    "        self.linear2 = nn.Linear(20 , 10)\n",
    "        self.act2    = nn.Softmax(dim=1)\n",
    "        \n",
    "        self.norm    = nn.LayerNorm()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "        \n",
    "    ## perform inference\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x            = self.linear1(x)\n",
    "        x            = self.act1(x)\n",
    "        x            = self.norm(x)\n",
    "        x            = self.dropout(x)\n",
    "        \n",
    "        x            = self.linear2(x)\n",
    "        y_pred       = self.act2(x)\n",
    "        \n",
    "        return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def training_loop( N_Epochs, model, loss_fn, opt ):\n",
    "    for epoch in range(N_Epochs):\n",
    "        for xb, yb in train_dl:\n",
    "            \n",
    "            ## xb = xb.view(  (16, -1 ) )\n",
    "            \n",
    "            xb = xb.to( torch_device )\n",
    "            yb = yb.to( torch_device )\n",
    "            \n",
    "            y_pred = model(xb)\n",
    "            \n",
    "            loss = loss_fn(y_pred, yb)\n",
    "            \n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        \n",
    "        if epoch % 5 == 0:\n",
    "            print(epoch, \"loss=\", loss)\n",
    "            new_PATH = PATH + str(epoch)\n",
    "            print( new_PATH )\n",
    "            torch.save(model, new_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## torch.save(model, PATH)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Core functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "N_Epochs      = 100\n",
    "learning_rate = 0.003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## model = MLP_net()\n",
    "## model =  DL_3h_net()\n",
    "\n",
    "model = CNNN_net()\n",
    "\n",
    "model.to( torch_device )\n",
    "\n",
    "opt = torch.optim.Adam(  model.parameters(), lr=learning_rate  )\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss= tensor(1.6404, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/scratch/scholar/huizarn/CNN_model_CIFAR100\n",
      "5 loss= tensor(0.6850, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/scratch/scholar/huizarn/CNN_model_CIFAR105\n",
      "10 loss= tensor(0.7441, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/scratch/scholar/huizarn/CNN_model_CIFAR1010\n",
      "15 loss= tensor(0.5707, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/scratch/scholar/huizarn/CNN_model_CIFAR1015\n",
      "20 loss= tensor(0.4392, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/scratch/scholar/huizarn/CNN_model_CIFAR1020\n",
      "25 loss= tensor(0.2742, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/scratch/scholar/huizarn/CNN_model_CIFAR1025\n",
      "30 loss= tensor(0.6219, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/scratch/scholar/huizarn/CNN_model_CIFAR1030\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-250-0e389010e1ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtraining_loop\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mN_Epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-246-4ad24d28f307>\u001b[0m in \u001b[0;36mtraining_loop\u001b[0;34m(N_Epochs, model, loss_fn, opt)\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0;31m## xb = xb.view(  (16, -1 ) )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0mxb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mtorch_device\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mtorch_device\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "training_loop( N_Epochs, model, loss_fn, opt )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_metrics_function(y_test, y_pred):\n",
    "    print('Accuracy: %.2f' % accuracy_score(y_test, y_pred))\n",
    "    confmat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confmat)\n",
    "    print('Precision: %.3f' % precision_score(y_true=y_test, y_pred=y_pred, average='weighted'))\n",
    "    print('Recall: %.3f' % recall_score(y_true=y_test, y_pred=y_pred, average='weighted'))\n",
    "    print('F1-measure: %.3f' % f1_score(y_true=y_test, y_pred=y_pred, average='weighted'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.80\n",
      "Confusion Matrix:\n",
      "[[814  10  36  20  17   1   5   7  63  27]\n",
      " [ 11 907   4   3   1   4  11   4   9  46]\n",
      " [ 48   0 719  49  61  49  53   9  11   1]\n",
      " [ 15   4  62 643  41 137  60  22   7   9]\n",
      " [  8   1  67  37 793  25  32  30   6   1]\n",
      " [  6   1  45 164  43 677  20  36   7   1]\n",
      " [  6   1  38  43  29  14 862   0   4   3]\n",
      " [ 11   3  23  41  70  37   4 801   2   8]\n",
      " [ 33  20   7  10   8   0   5   1 898  18]\n",
      " [ 23  53   6  13   7   3   7   8  18 862]]\n",
      "Precision: 0.799\n",
      "Recall: 0.798\n",
      "F1-measure: 0.798\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with torch.no_grad():\n",
    "    for x_real, y_real in test_dl:\n",
    "        \n",
    "        batch_size = x_real.shape[0]\n",
    "        \n",
    "        ## x_real = x_real.view(  (batch_size, -1 ) )\n",
    "        \n",
    "        x_real = x_real.to( torch_device )\n",
    "        \n",
    "        y_pred = model(  x_real  )\n",
    "        \n",
    "        vals, indeces = torch.max( y_pred, dim=1  )\n",
    "        preds = indeces\n",
    "        print_metrics_function( y_real, preds.cpu() )\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## From checkpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Model class must be defined somewhere\n",
    "model2 = torch.load('/scratch/scholar/huizarn/CNN_model_CIFAR1010860')\n",
    "## model.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with torch.no_grad():\n",
    "    for x_real, y_real in test_dl:\n",
    "        \n",
    "        batch_size = x_real.shape[0]\n",
    "        \n",
    "        ## x_real = x_real.view(  (batch_size, -1 ) )\n",
    "        \n",
    "        y_pred = model2(  x_real  )\n",
    "        \n",
    "        vals, indeces = torch.max( y_pred, dim=1  )\n",
    "        preds = indeces\n",
    "        print_metrics_function(y_real, preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rc = data_train[4].view((-1))\n",
    "rc.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rc = torch.unsqueeze(rc, dim=0)\n",
    "rc.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## example_label = model( rc )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## example_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Figure out the dimensions of CNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "N_batches_rc = 256\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "model_rc = nn.Sequential(\n",
    "            \n",
    "            ## conv layer 1\n",
    "            nn.Conv2d(3, 16, kernel_size=5, stride=1, padding=1  ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), \n",
    "            \n",
    "            ## conv layer 2\n",
    "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=1  ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), \n",
    "              \n",
    "            ## FeedForward\n",
    "            \n",
    "            nn.Flatten()\n",
    "            \n",
    "            \n",
    "        \n",
    "        )\n",
    "        \n",
    "'''\n",
    "\n",
    "\n",
    "model_rc  = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            \n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(2, 2), # output: 64 x 16 x 16\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            \n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(2, 2), # output: 128 x 8 x 8\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(2, 2), # output: 128 x 8 x 8\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ELU(),\n",
    "            nn.BatchNorm2d(256),\n",
    "            \n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.GELU(),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.MaxPool2d(2, 2), # output: 256 x 4 x 4\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.MaxPool2d(2, 2), # output: 256 x 4 x 4\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.Flatten()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "my_tensor_test   = torch.randn(N_batches_rc, 3, 32,  32)\n",
    "\n",
    "res_actual_model = model_rc(  my_tensor_test   )\n",
    "\n",
    "res_actual_model.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (Anaconda 2020.02)",
   "language": "python",
   "name": "anaconda-2020.02-py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
